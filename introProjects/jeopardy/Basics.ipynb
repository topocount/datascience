{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show_Number', 'Air_Date', 'Round', 'Category', 'Value', 'Question', 'Answer'], dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "#print(jeopardy.head())\n",
    "jeopardy.columns = ['Show_Number', 'Air_Date', 'Round', 'Category', 'Value', 'Question', 'Answer']\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Cleaning\n",
    "\n",
    "Removing all characters from the question and answer strings that aren't lowercase alphanumeric or whitespace characters. Additionally, date values in the Air_Date column are converted to datetime objects so they can be sorted and organized more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^A-Za-z0-9\\s]','',text)\n",
    "    return text\n",
    "jeopardy['clean_question'] = jeopardy['Question'].apply(clean_text)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_val(text):\n",
    "    text = re.sub('[^A-Za-z0-9\\s]','',text)\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except Exception:\n",
    "        text = 0\n",
    "    return text\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(clean_val)\n",
    "jeopardy['Air_Date'] = pd.to_datetime(jeopardy['Air_Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer In Question\n",
    "The counter function is designed to tablulate the number of words in an answer that are also used in a question, while excluding the word 'the'. The average number of words shared between questions and answers in this dataset is calculated to be 5.8%\n",
    "\n",
    "If 5.8% of words in an answer match the words in a question, then it is safe to explore an alternative study source. The other 94% needs to come from somewhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def counter(row):\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question = row['clean_question'].split()\n",
    "    match_count = 0\n",
    "    for i in split_answer: \n",
    "        if i == 'the': split_answer.remove('the')\n",
    "    if len(split_answer) == 0: return 0\n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            match_count += 1\n",
    "    return match_count / len(split_answer)\n",
    "jeopardy['answer_in_question'] = jeopardy.apply(counter,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0583474447893\n"
     ]
    }
   ],
   "source": [
    "print(jeopardy['answer_in_question'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recycled Questions\n",
    "It appears that many words in questions are definitely reused, since this calculation shows nearly 70%. However, the words have not been grouped in any way, so we can't be too sure of how much of a role something like question formulation impacts this result.\n",
    "\n",
    "It is evident, however, that further exploration in the reuse of questions is worthwhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.689403135907\n"
     ]
    }
   ],
   "source": [
    "jeopardy.sort('Air_Date',inplace=True)\n",
    "terms_used = set()\n",
    "question_overlap = []\n",
    "for i, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    split_question = [q for q in split_question if len(q) > 5]\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used: match_count += 1\n",
    "        else: terms_used.add(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "jeopardy['question_overlap'] = question_overlap\n",
    "print(jeopardy['question_overlap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low v. High Value Questions\n",
    "\n",
    "Several of the sample words had p values that indicated a significant difference in distribution between low and high value questions. However, because the sample size is so small, the results are unereliable. More words should be sampled, and more questions are probably needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0), (1, 2), (1, 1), (3, 0), (1, 0)]\n"
     ]
    }
   ],
   "source": [
    "def valcheck(row):\n",
    "    if row['clean_value'] > 800: value = 1\n",
    "    else: value = 0\n",
    "    return value\n",
    "jeopardy['high_value'] = jeopardy.apply(valcheck,axis=1)\n",
    "\n",
    "def valcount(word):\n",
    "    low_count, high_count = 0, 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        split_question = row['clean_question'].split(' ')\n",
    "        if word in split_question:\n",
    "            if row['high_value']: high_count += 1\n",
    "            else: low_count += 1\n",
    "    return low_count, high_count\n",
    "\n",
    "observed_expected = []\n",
    "comparison_terms = list(terms_used)[:5]\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(valcount(term))\n",
    "\n",
    "print(observed_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5734\n",
      "14265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4.9755842343913503, 0.025707519787911092),\n",
       " (0.81912870034064222, 0.36543503656640786),\n",
       " (3.6985364233317939, 0.05446021891391202),\n",
       " (7.1390129054761076, 0.0075424665032683604),\n",
       " (9.3170720106541527, 0.0022702849666422693)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "high_value_count = jeopardy[jeopardy['high_value']==1].shape[0]\n",
    "print(high_value_count)\n",
    "low_value_count = jeopardy[jeopardy['high_value']==0].shape[0]\n",
    "print(low_value_count)\n",
    "\n",
    "chi_squared = []\n",
    "total = 0\n",
    "for row in observed_expected:\n",
    "    total += row[0] + row[1]\n",
    "    total_prop = total / (high_value_count + low_value_count)\n",
    "\n",
    "    ehi = total_prop * high_value_count\n",
    "    elo = total_prop * low_value_count\n",
    "    obs = np.array([row[0],row[1]])\n",
    "    exp = np.array([ehi,elo])\n",
    "    chi_squared.append(chisquare(obs,exp))\n",
    "\n",
    "\n",
    "chi_squared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
